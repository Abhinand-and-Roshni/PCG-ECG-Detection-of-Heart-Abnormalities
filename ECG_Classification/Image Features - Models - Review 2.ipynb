{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f092e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa8ce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>energy</th>\n",
       "      <th>statistics_energy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_deviation</th>\n",
       "      <th>median</th>\n",
       "      <th>img_range</th>\n",
       "      <th>...</th>\n",
       "      <th>imc2</th>\n",
       "      <th>idmn</th>\n",
       "      <th>idn</th>\n",
       "      <th>inverse_variance</th>\n",
       "      <th>maximum_probability</th>\n",
       "      <th>sum_average</th>\n",
       "      <th>sum_entropy</th>\n",
       "      <th>sum_varianc</th>\n",
       "      <th>variance.1</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e01661</td>\n",
       "      <td>14096328</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.164467</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.440368</td>\n",
       "      <td>117.348702</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.878740</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>18.036460</td>\n",
       "      <td>1.677938</td>\n",
       "      <td>299.260348</td>\n",
       "      <td>94.838742</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0122</td>\n",
       "      <td>5756791</td>\n",
       "      <td>3.508266e+10</td>\n",
       "      <td>1.149228</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.781019</td>\n",
       "      <td>118.821733</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599783</td>\n",
       "      <td>0.903181</td>\n",
       "      <td>0.881726</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.631226</td>\n",
       "      <td>17.975607</td>\n",
       "      <td>1.654042</td>\n",
       "      <td>299.968422</td>\n",
       "      <td>94.824249</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0022</td>\n",
       "      <td>13859401</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.168703</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.913443</td>\n",
       "      <td>117.430662</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696438</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.879477</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0.626256</td>\n",
       "      <td>18.075714</td>\n",
       "      <td>1.673771</td>\n",
       "      <td>300.354564</td>\n",
       "      <td>95.023116</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e01846</td>\n",
       "      <td>13573243</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.189315</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.615798</td>\n",
       "      <td>116.124833</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744144</td>\n",
       "      <td>0.903104</td>\n",
       "      <td>0.878379</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.624557</td>\n",
       "      <td>18.109670</td>\n",
       "      <td>1.668156</td>\n",
       "      <td>300.674627</td>\n",
       "      <td>95.085496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a0320</td>\n",
       "      <td>4365269</td>\n",
       "      <td>3.662849e+10</td>\n",
       "      <td>1.156185</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.118612</td>\n",
       "      <td>119.181668</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608799</td>\n",
       "      <td>0.898177</td>\n",
       "      <td>0.878095</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.642330</td>\n",
       "      <td>18.306196</td>\n",
       "      <td>1.507210</td>\n",
       "      <td>311.686159</td>\n",
       "      <td>96.625613</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>e00572</td>\n",
       "      <td>14570919</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.187961</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.835780</td>\n",
       "      <td>116.266456</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741029</td>\n",
       "      <td>0.903743</td>\n",
       "      <td>0.879461</td>\n",
       "      <td>0.026624</td>\n",
       "      <td>0.623884</td>\n",
       "      <td>18.078773</td>\n",
       "      <td>1.706188</td>\n",
       "      <td>299.014988</td>\n",
       "      <td>94.910106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>e00214</td>\n",
       "      <td>13103016</td>\n",
       "      <td>2.150000e+11</td>\n",
       "      <td>1.158585</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.209891</td>\n",
       "      <td>117.967900</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671326</td>\n",
       "      <td>0.900854</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>0.626397</td>\n",
       "      <td>18.064612</td>\n",
       "      <td>1.639206</td>\n",
       "      <td>301.226450</td>\n",
       "      <td>95.060359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>e00200</td>\n",
       "      <td>12914430</td>\n",
       "      <td>2.210000e+11</td>\n",
       "      <td>1.146299</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>148.600780</td>\n",
       "      <td>118.666931</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664847</td>\n",
       "      <td>0.899625</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.626777</td>\n",
       "      <td>18.044109</td>\n",
       "      <td>1.623775</td>\n",
       "      <td>301.438278</td>\n",
       "      <td>95.011709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>e00566</td>\n",
       "      <td>14112484</td>\n",
       "      <td>1.780000e+11</td>\n",
       "      <td>1.253403</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>154.022398</td>\n",
       "      <td>113.506337</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.903545</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.622184</td>\n",
       "      <td>18.275741</td>\n",
       "      <td>1.674930</td>\n",
       "      <td>303.210042</td>\n",
       "      <td>95.589052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>e01678</td>\n",
       "      <td>13889134</td>\n",
       "      <td>1.810000e+11</td>\n",
       "      <td>1.239996</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>153.359814</td>\n",
       "      <td>114.124315</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.623666</td>\n",
       "      <td>18.260199</td>\n",
       "      <td>1.661096</td>\n",
       "      <td>303.428511</td>\n",
       "      <td>95.542554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patientid    energy  statistics_energy  kurtosis  maximum  minimum  \\\n",
       "0       e01661  14096328       2.070000e+11  1.164467      255        0   \n",
       "1        a0122   5756791       3.508266e+10  1.149228      255        0   \n",
       "2        b0022  13859401       2.070000e+11  1.168703      255        0   \n",
       "3       e01846  13573243       1.970000e+11  1.189315      255        0   \n",
       "4        a0320   4365269       3.662849e+10  1.156185      255        0   \n",
       "...        ...       ...                ...       ...      ...      ...   \n",
       "3235    e00572  14570919       1.970000e+11  1.187961      255        0   \n",
       "3236    e00214  13103016       2.150000e+11  1.158585      255        0   \n",
       "3237    e00200  12914430       2.210000e+11  1.146299      255        0   \n",
       "3238    e00566  14112484       1.780000e+11  1.253403      255        0   \n",
       "3239    e01678  13889134       1.810000e+11  1.239996      255        0   \n",
       "\n",
       "            mean  mean_deviation  median  img_range  ...      imc2      idmn  \\\n",
       "0     149.440368      117.348702     255        255  ...  0.698198  0.902554   \n",
       "1     149.781019      118.821733     255        255  ...  0.599783  0.903181   \n",
       "2     149.913443      117.430662     255        255  ...  0.696438  0.902344   \n",
       "3     150.615798      116.124833     255        255  ...  0.744144  0.903104   \n",
       "4     150.118612      119.181668     255        255  ...  0.608799  0.898177   \n",
       "...          ...             ...     ...        ...  ...       ...       ...   \n",
       "3235  150.835780      116.266456     255        255  ...  0.741029  0.903743   \n",
       "3236  149.209891      117.967900     255        255  ...  0.671326  0.900854   \n",
       "3237  148.600780      118.666931     255        255  ...  0.664847  0.899625   \n",
       "3238  154.022398      113.506337     255        255  ...  0.825000  0.903545   \n",
       "3239  153.359814      114.124315     255        255  ...  0.817985  0.903332   \n",
       "\n",
       "           idn  inverse_variance  maximum_probability  sum_average  \\\n",
       "0     0.878740          0.026416             0.625243    18.036460   \n",
       "1     0.881726          0.030142             0.631226    17.975607   \n",
       "2     0.879477          0.026135             0.626256    18.075714   \n",
       "3     0.878379          0.024142             0.624557    18.109670   \n",
       "4     0.878095          0.020102             0.642330    18.306196   \n",
       "...        ...               ...                  ...          ...   \n",
       "3235  0.879461          0.026624             0.623884    18.078773   \n",
       "3236  0.878392          0.023878             0.626397    18.064612   \n",
       "3237  0.878273          0.023454             0.626777    18.044109   \n",
       "3238  0.878261          0.023997             0.622184    18.275741   \n",
       "3239  0.878428          0.022315             0.623666    18.260199   \n",
       "\n",
       "      sum_entropy  sum_varianc  variance.1  HYPOTHESIS  \n",
       "0        1.677938   299.260348   94.838742          -1  \n",
       "1        1.654042   299.968422   94.824249          -1  \n",
       "2        1.673771   300.354564   95.023116          -1  \n",
       "3        1.668156   300.674627   95.085496          -1  \n",
       "4        1.507210   311.686159   96.625613          -1  \n",
       "...           ...          ...         ...         ...  \n",
       "3235     1.706188   299.014988   94.910106           1  \n",
       "3236     1.639206   301.226450   95.060359           1  \n",
       "3237     1.623775   301.438278   95.011709           1  \n",
       "3238     1.674930   303.210042   95.589052           1  \n",
       "3239     1.661096   303.428511   95.542554           1  \n",
       "\n",
       "[3240 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Roshni/OneDrive/Desktop/Sem7/Project 1/physionet spectro/PhysioNet-PCG-ImageFeatures.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08e0b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3240 entries, 0 to 3239\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   patientid            3240 non-null   object \n",
      " 1   energy               3240 non-null   int64  \n",
      " 2   statistics_energy    3240 non-null   float64\n",
      " 3   kurtosis             3240 non-null   float64\n",
      " 4   maximum              3240 non-null   int64  \n",
      " 5   minimum              3240 non-null   int64  \n",
      " 6   mean                 3240 non-null   float64\n",
      " 7   mean_deviation       3240 non-null   float64\n",
      " 8   median               3240 non-null   int64  \n",
      " 9   img_range            3240 non-null   int64  \n",
      " 10  rms                  3240 non-null   float64\n",
      " 11  skewness             3240 non-null   float64\n",
      " 12  std                  3240 non-null   float64\n",
      " 13  variance             3240 non-null   float64\n",
      " 14  entropy              3240 non-null   float64\n",
      " 15  uniformity           3240 non-null   float64\n",
      " 16  autocorrelation      3240 non-null   float64\n",
      " 17  cluster_prominence   3240 non-null   float64\n",
      " 18  cluster_shade        3240 non-null   float64\n",
      " 19  cluster_tendency     3240 non-null   float64\n",
      " 20  contrast             3240 non-null   float64\n",
      " 21  correlation          3240 non-null   float64\n",
      " 22  difference_entropy   3240 non-null   float64\n",
      " 23  dissimilarity        3240 non-null   float64\n",
      " 24  glcm_energy          3240 non-null   float64\n",
      " 25  glcm_entropy         3240 non-null   float64\n",
      " 26  homogeneity1         3240 non-null   float64\n",
      " 27  imc1                 3240 non-null   float64\n",
      " 28  imc2                 3240 non-null   float64\n",
      " 29  idmn                 3240 non-null   float64\n",
      " 30  idn                  3240 non-null   float64\n",
      " 31  inverse_variance     3240 non-null   float64\n",
      " 32  maximum_probability  3240 non-null   float64\n",
      " 33  sum_average          3240 non-null   float64\n",
      " 34  sum_entropy          3240 non-null   float64\n",
      " 35  sum_varianc          3240 non-null   float64\n",
      " 36  variance.1           3240 non-null   float64\n",
      " 37  HYPOTHESIS           3240 non-null   int64  \n",
      "dtypes: float64(31), int64(6), object(1)\n",
      "memory usage: 962.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc4d4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "accuracies_with_PCA_axes=[]\n",
    "accuracies_combined=[]\n",
    "only_dataset=[]\n",
    "\n",
    "X=df.iloc[:,1:-1]\n",
    "y=df[['HYPOTHESIS']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "clf=AdaBoostClassifier(random_state=96,base_estimator=RandomForestClassifier(random_state=101),n_estimators=100,learning_rate=0.01)\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "for i in range(1,37):\n",
    "    only_dataset.append(clf.score(X_test,y_test))\n",
    "\n",
    "for i in range(1,37):\n",
    "    print(\"ITERATION \"+str(i+1))\n",
    "    X=df.iloc[:,1:-1]\n",
    "    y=df[['HYPOTHESIS']]\n",
    "    pca=PCA(n_components=i)\n",
    "    X_PCA=pca.fit_transform(X)\n",
    "    X_PCA=pd.DataFrame(X_PCA)\n",
    "    FINAL_X_SET = pd.concat([X, X_PCA], axis=1, join='inner')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(FINAL_X_SET, y, test_size = 0.2, random_state = 1)\n",
    "    clf=AdaBoostClassifier(random_state=96,base_estimator=RandomForestClassifier(random_state=101),n_estimators=100,learning_rate=0.01)\n",
    "    clf.fit(X_train, y_train.values.ravel()) \n",
    "    accuracies_combined.append(clf.score(X_test,y_test))\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_PCA, y, test_size=0.2, random_state=1)\n",
    "    clf=AdaBoostClassifier(random_state=96,base_estimator=RandomForestClassifier(random_state=101),n_estimators=100,learning_rate=0.01)\n",
    "    clf.fit(X_train,y_train.values.ravel())\n",
    "    accuracies_with_PCA_axes.append(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b4668c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams['font.size'] = 12\n",
    "csfont = {'fontname':'Times New Roman'}\n",
    "plt.plot(accuracies_with_PCA_axes,color='b',label='only PCA AXES')\n",
    "plt.plot(accuracies_combined, color='r',label='PCA + DATASET')\n",
    "plt.plot(only_dataset,color='g',label='ONLY DATASET')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration',**csfont)\n",
    "plt.ylabel('Accuracy',**csfont)\n",
    "plt.savefig(\"Image_Features_PCG.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc007c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77117e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7603125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>energy</th>\n",
       "      <th>statistics_energy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_deviation</th>\n",
       "      <th>median</th>\n",
       "      <th>img_range</th>\n",
       "      <th>...</th>\n",
       "      <th>imc2</th>\n",
       "      <th>idmn</th>\n",
       "      <th>idn</th>\n",
       "      <th>inverse_variance</th>\n",
       "      <th>maximum_probability</th>\n",
       "      <th>sum_average</th>\n",
       "      <th>sum_entropy</th>\n",
       "      <th>sum_varianc</th>\n",
       "      <th>variance.1</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e01661</td>\n",
       "      <td>14096328</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.164467</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.440368</td>\n",
       "      <td>117.348702</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.878740</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>18.036460</td>\n",
       "      <td>1.677938</td>\n",
       "      <td>299.260348</td>\n",
       "      <td>94.838742</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0122</td>\n",
       "      <td>5756791</td>\n",
       "      <td>3.508266e+10</td>\n",
       "      <td>1.149228</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.781019</td>\n",
       "      <td>118.821733</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599783</td>\n",
       "      <td>0.903181</td>\n",
       "      <td>0.881726</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.631226</td>\n",
       "      <td>17.975607</td>\n",
       "      <td>1.654042</td>\n",
       "      <td>299.968422</td>\n",
       "      <td>94.824249</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0022</td>\n",
       "      <td>13859401</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.168703</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.913443</td>\n",
       "      <td>117.430662</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696438</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.879477</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0.626256</td>\n",
       "      <td>18.075714</td>\n",
       "      <td>1.673771</td>\n",
       "      <td>300.354564</td>\n",
       "      <td>95.023116</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e01846</td>\n",
       "      <td>13573243</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.189315</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.615798</td>\n",
       "      <td>116.124833</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744144</td>\n",
       "      <td>0.903104</td>\n",
       "      <td>0.878379</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.624557</td>\n",
       "      <td>18.109670</td>\n",
       "      <td>1.668156</td>\n",
       "      <td>300.674627</td>\n",
       "      <td>95.085496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a0320</td>\n",
       "      <td>4365269</td>\n",
       "      <td>3.662849e+10</td>\n",
       "      <td>1.156185</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.118612</td>\n",
       "      <td>119.181668</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608799</td>\n",
       "      <td>0.898177</td>\n",
       "      <td>0.878095</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.642330</td>\n",
       "      <td>18.306196</td>\n",
       "      <td>1.507210</td>\n",
       "      <td>311.686159</td>\n",
       "      <td>96.625613</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>e00572</td>\n",
       "      <td>14570919</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.187961</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.835780</td>\n",
       "      <td>116.266456</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741029</td>\n",
       "      <td>0.903743</td>\n",
       "      <td>0.879461</td>\n",
       "      <td>0.026624</td>\n",
       "      <td>0.623884</td>\n",
       "      <td>18.078773</td>\n",
       "      <td>1.706188</td>\n",
       "      <td>299.014988</td>\n",
       "      <td>94.910106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>e00214</td>\n",
       "      <td>13103016</td>\n",
       "      <td>2.150000e+11</td>\n",
       "      <td>1.158585</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.209891</td>\n",
       "      <td>117.967900</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671326</td>\n",
       "      <td>0.900854</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>0.626397</td>\n",
       "      <td>18.064612</td>\n",
       "      <td>1.639206</td>\n",
       "      <td>301.226450</td>\n",
       "      <td>95.060359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>e00200</td>\n",
       "      <td>12914430</td>\n",
       "      <td>2.210000e+11</td>\n",
       "      <td>1.146299</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>148.600780</td>\n",
       "      <td>118.666931</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664847</td>\n",
       "      <td>0.899625</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.626777</td>\n",
       "      <td>18.044109</td>\n",
       "      <td>1.623775</td>\n",
       "      <td>301.438278</td>\n",
       "      <td>95.011709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>e00566</td>\n",
       "      <td>14112484</td>\n",
       "      <td>1.780000e+11</td>\n",
       "      <td>1.253403</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>154.022398</td>\n",
       "      <td>113.506337</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.903545</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.622184</td>\n",
       "      <td>18.275741</td>\n",
       "      <td>1.674930</td>\n",
       "      <td>303.210042</td>\n",
       "      <td>95.589052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>e01678</td>\n",
       "      <td>13889134</td>\n",
       "      <td>1.810000e+11</td>\n",
       "      <td>1.239996</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>153.359814</td>\n",
       "      <td>114.124315</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.623666</td>\n",
       "      <td>18.260199</td>\n",
       "      <td>1.661096</td>\n",
       "      <td>303.428511</td>\n",
       "      <td>95.542554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patientid    energy  statistics_energy  kurtosis  maximum  minimum  \\\n",
       "0       e01661  14096328       2.070000e+11  1.164467      255        0   \n",
       "1        a0122   5756791       3.508266e+10  1.149228      255        0   \n",
       "2        b0022  13859401       2.070000e+11  1.168703      255        0   \n",
       "3       e01846  13573243       1.970000e+11  1.189315      255        0   \n",
       "4        a0320   4365269       3.662849e+10  1.156185      255        0   \n",
       "...        ...       ...                ...       ...      ...      ...   \n",
       "3235    e00572  14570919       1.970000e+11  1.187961      255        0   \n",
       "3236    e00214  13103016       2.150000e+11  1.158585      255        0   \n",
       "3237    e00200  12914430       2.210000e+11  1.146299      255        0   \n",
       "3238    e00566  14112484       1.780000e+11  1.253403      255        0   \n",
       "3239    e01678  13889134       1.810000e+11  1.239996      255        0   \n",
       "\n",
       "            mean  mean_deviation  median  img_range  ...      imc2      idmn  \\\n",
       "0     149.440368      117.348702     255        255  ...  0.698198  0.902554   \n",
       "1     149.781019      118.821733     255        255  ...  0.599783  0.903181   \n",
       "2     149.913443      117.430662     255        255  ...  0.696438  0.902344   \n",
       "3     150.615798      116.124833     255        255  ...  0.744144  0.903104   \n",
       "4     150.118612      119.181668     255        255  ...  0.608799  0.898177   \n",
       "...          ...             ...     ...        ...  ...       ...       ...   \n",
       "3235  150.835780      116.266456     255        255  ...  0.741029  0.903743   \n",
       "3236  149.209891      117.967900     255        255  ...  0.671326  0.900854   \n",
       "3237  148.600780      118.666931     255        255  ...  0.664847  0.899625   \n",
       "3238  154.022398      113.506337     255        255  ...  0.825000  0.903545   \n",
       "3239  153.359814      114.124315     255        255  ...  0.817985  0.903332   \n",
       "\n",
       "           idn  inverse_variance  maximum_probability  sum_average  \\\n",
       "0     0.878740          0.026416             0.625243    18.036460   \n",
       "1     0.881726          0.030142             0.631226    17.975607   \n",
       "2     0.879477          0.026135             0.626256    18.075714   \n",
       "3     0.878379          0.024142             0.624557    18.109670   \n",
       "4     0.878095          0.020102             0.642330    18.306196   \n",
       "...        ...               ...                  ...          ...   \n",
       "3235  0.879461          0.026624             0.623884    18.078773   \n",
       "3236  0.878392          0.023878             0.626397    18.064612   \n",
       "3237  0.878273          0.023454             0.626777    18.044109   \n",
       "3238  0.878261          0.023997             0.622184    18.275741   \n",
       "3239  0.878428          0.022315             0.623666    18.260199   \n",
       "\n",
       "      sum_entropy  sum_varianc  variance.1  HYPOTHESIS  \n",
       "0        1.677938   299.260348   94.838742          -1  \n",
       "1        1.654042   299.968422   94.824249          -1  \n",
       "2        1.673771   300.354564   95.023116          -1  \n",
       "3        1.668156   300.674627   95.085496          -1  \n",
       "4        1.507210   311.686159   96.625613          -1  \n",
       "...           ...          ...         ...         ...  \n",
       "3235     1.706188   299.014988   94.910106           1  \n",
       "3236     1.639206   301.226450   95.060359           1  \n",
       "3237     1.623775   301.438278   95.011709           1  \n",
       "3238     1.674930   303.210042   95.589052           1  \n",
       "3239     1.661096   303.428511   95.542554           1  \n",
       "\n",
       "[3240 rows x 38 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1438ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>statistics_energy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_deviation</th>\n",
       "      <th>median</th>\n",
       "      <th>img_range</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>imc1</th>\n",
       "      <th>imc2</th>\n",
       "      <th>idmn</th>\n",
       "      <th>idn</th>\n",
       "      <th>inverse_variance</th>\n",
       "      <th>maximum_probability</th>\n",
       "      <th>sum_average</th>\n",
       "      <th>sum_entropy</th>\n",
       "      <th>sum_varianc</th>\n",
       "      <th>variance.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14096328</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.164467</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.440368</td>\n",
       "      <td>117.348702</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.386978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356743</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.878740</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>18.036460</td>\n",
       "      <td>1.677938</td>\n",
       "      <td>299.260348</td>\n",
       "      <td>94.838742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5756791</td>\n",
       "      <td>3.508266e+10</td>\n",
       "      <td>1.149228</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.781019</td>\n",
       "      <td>118.821733</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.401121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296338</td>\n",
       "      <td>0.599783</td>\n",
       "      <td>0.903181</td>\n",
       "      <td>0.881726</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.631226</td>\n",
       "      <td>17.975607</td>\n",
       "      <td>1.654042</td>\n",
       "      <td>299.968422</td>\n",
       "      <td>94.824249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13859401</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>1.168703</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.913443</td>\n",
       "      <td>117.430662</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.358394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363127</td>\n",
       "      <td>0.696438</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.879477</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0.626256</td>\n",
       "      <td>18.075714</td>\n",
       "      <td>1.673771</td>\n",
       "      <td>300.354564</td>\n",
       "      <td>95.023116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13573243</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.189315</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.615798</td>\n",
       "      <td>116.124833</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.323542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391104</td>\n",
       "      <td>0.744144</td>\n",
       "      <td>0.903104</td>\n",
       "      <td>0.878379</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.624557</td>\n",
       "      <td>18.109670</td>\n",
       "      <td>1.668156</td>\n",
       "      <td>300.674627</td>\n",
       "      <td>95.085496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4365269</td>\n",
       "      <td>3.662849e+10</td>\n",
       "      <td>1.156185</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.118612</td>\n",
       "      <td>119.181668</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>2.961675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303360</td>\n",
       "      <td>0.608799</td>\n",
       "      <td>0.898177</td>\n",
       "      <td>0.878095</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.642330</td>\n",
       "      <td>18.306196</td>\n",
       "      <td>1.507210</td>\n",
       "      <td>311.686159</td>\n",
       "      <td>96.625613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>14570919</td>\n",
       "      <td>1.970000e+11</td>\n",
       "      <td>1.187961</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>150.835780</td>\n",
       "      <td>116.266456</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.443522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392216</td>\n",
       "      <td>0.741029</td>\n",
       "      <td>0.903743</td>\n",
       "      <td>0.879461</td>\n",
       "      <td>0.026624</td>\n",
       "      <td>0.623884</td>\n",
       "      <td>18.078773</td>\n",
       "      <td>1.706188</td>\n",
       "      <td>299.014988</td>\n",
       "      <td>94.910106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>13103016</td>\n",
       "      <td>2.150000e+11</td>\n",
       "      <td>1.158585</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>149.209891</td>\n",
       "      <td>117.967900</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.265465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342972</td>\n",
       "      <td>0.671326</td>\n",
       "      <td>0.900854</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>0.626397</td>\n",
       "      <td>18.064612</td>\n",
       "      <td>1.639206</td>\n",
       "      <td>301.226450</td>\n",
       "      <td>95.060359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>12914430</td>\n",
       "      <td>2.210000e+11</td>\n",
       "      <td>1.146299</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>148.600780</td>\n",
       "      <td>118.666931</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.241881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338133</td>\n",
       "      <td>0.664847</td>\n",
       "      <td>0.899625</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.626777</td>\n",
       "      <td>18.044109</td>\n",
       "      <td>1.623775</td>\n",
       "      <td>301.438278</td>\n",
       "      <td>95.011709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>14112484</td>\n",
       "      <td>1.780000e+11</td>\n",
       "      <td>1.253403</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>154.022398</td>\n",
       "      <td>113.506337</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.388919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468327</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.903545</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.622184</td>\n",
       "      <td>18.275741</td>\n",
       "      <td>1.674930</td>\n",
       "      <td>303.210042</td>\n",
       "      <td>95.589052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>13889134</td>\n",
       "      <td>1.810000e+11</td>\n",
       "      <td>1.239996</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>153.359814</td>\n",
       "      <td>114.124315</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>3.361994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462864</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.623666</td>\n",
       "      <td>18.260199</td>\n",
       "      <td>1.661096</td>\n",
       "      <td>303.428511</td>\n",
       "      <td>95.542554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        energy  statistics_energy  kurtosis  maximum  minimum        mean  \\\n",
       "0     14096328       2.070000e+11  1.164467      255        0  149.440368   \n",
       "1      5756791       3.508266e+10  1.149228      255        0  149.781019   \n",
       "2     13859401       2.070000e+11  1.168703      255        0  149.913443   \n",
       "3     13573243       1.970000e+11  1.189315      255        0  150.615798   \n",
       "4      4365269       3.662849e+10  1.156185      255        0  150.118612   \n",
       "...        ...                ...       ...      ...      ...         ...   \n",
       "3235  14570919       1.970000e+11  1.187961      255        0  150.835780   \n",
       "3236  13103016       2.150000e+11  1.158585      255        0  149.209891   \n",
       "3237  12914430       2.210000e+11  1.146299      255        0  148.600780   \n",
       "3238  14112484       1.780000e+11  1.253403      255        0  154.022398   \n",
       "3239  13889134       1.810000e+11  1.239996      255        0  153.359814   \n",
       "\n",
       "      mean_deviation  median  img_range       rms  ...      imc1      imc2  \\\n",
       "0         117.348702     255        255  3.386978  ... -0.356743  0.698198   \n",
       "1         118.821733     255        255  3.401121  ... -0.296338  0.599783   \n",
       "2         117.430662     255        255  3.358394  ... -0.363127  0.696438   \n",
       "3         116.124833     255        255  3.323542  ... -0.391104  0.744144   \n",
       "4         119.181668     255        255  2.961675  ... -0.303360  0.608799   \n",
       "...              ...     ...        ...       ...  ...       ...       ...   \n",
       "3235      116.266456     255        255  3.443522  ... -0.392216  0.741029   \n",
       "3236      117.967900     255        255  3.265465  ... -0.342972  0.671326   \n",
       "3237      118.666931     255        255  3.241881  ... -0.338133  0.664847   \n",
       "3238      113.506337     255        255  3.388919  ... -0.468327  0.825000   \n",
       "3239      114.124315     255        255  3.361994  ... -0.462864  0.817985   \n",
       "\n",
       "          idmn       idn  inverse_variance  maximum_probability  sum_average  \\\n",
       "0     0.902554  0.878740          0.026416             0.625243    18.036460   \n",
       "1     0.903181  0.881726          0.030142             0.631226    17.975607   \n",
       "2     0.902344  0.879477          0.026135             0.626256    18.075714   \n",
       "3     0.903104  0.878379          0.024142             0.624557    18.109670   \n",
       "4     0.898177  0.878095          0.020102             0.642330    18.306196   \n",
       "...        ...       ...               ...                  ...          ...   \n",
       "3235  0.903743  0.879461          0.026624             0.623884    18.078773   \n",
       "3236  0.900854  0.878392          0.023878             0.626397    18.064612   \n",
       "3237  0.899625  0.878273          0.023454             0.626777    18.044109   \n",
       "3238  0.903545  0.878261          0.023997             0.622184    18.275741   \n",
       "3239  0.903332  0.878428          0.022315             0.623666    18.260199   \n",
       "\n",
       "      sum_entropy  sum_varianc  variance.1  \n",
       "0        1.677938   299.260348   94.838742  \n",
       "1        1.654042   299.968422   94.824249  \n",
       "2        1.673771   300.354564   95.023116  \n",
       "3        1.668156   300.674627   95.085496  \n",
       "4        1.507210   311.686159   96.625613  \n",
       "...           ...          ...         ...  \n",
       "3235     1.706188   299.014988   94.910106  \n",
       "3236     1.639206   301.226450   95.060359  \n",
       "3237     1.623775   301.438278   95.011709  \n",
       "3238     1.674930   303.210042   95.589052  \n",
       "3239     1.661096   303.428511   95.542554  \n",
       "\n",
       "[3240 rows x 36 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1f1a001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>statistics_energy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_deviation</th>\n",
       "      <th>median</th>\n",
       "      <th>img_range</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>imc1</th>\n",
       "      <th>imc2</th>\n",
       "      <th>idmn</th>\n",
       "      <th>idn</th>\n",
       "      <th>inverse_variance</th>\n",
       "      <th>maximum_probability</th>\n",
       "      <th>sum_average</th>\n",
       "      <th>sum_entropy</th>\n",
       "      <th>sum_varianc</th>\n",
       "      <th>variance.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861327</td>\n",
       "      <td>0.739775</td>\n",
       "      <td>0.276290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.298610</td>\n",
       "      <td>0.526440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592281</td>\n",
       "      <td>0.585547</td>\n",
       "      <td>0.614940</td>\n",
       "      <td>0.436165</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.112373</td>\n",
       "      <td>0.242410</td>\n",
       "      <td>0.885271</td>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.187416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192122</td>\n",
       "      <td>0.029662</td>\n",
       "      <td>0.228647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317524</td>\n",
       "      <td>0.647607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846544</td>\n",
       "      <td>0.314072</td>\n",
       "      <td>0.653534</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.691949</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.181031</td>\n",
       "      <td>0.837549</td>\n",
       "      <td>0.133114</td>\n",
       "      <td>0.184223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842315</td>\n",
       "      <td>0.739775</td>\n",
       "      <td>0.289534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324877</td>\n",
       "      <td>0.533181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565409</td>\n",
       "      <td>0.580694</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.513437</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>0.140795</td>\n",
       "      <td>0.282003</td>\n",
       "      <td>0.876948</td>\n",
       "      <td>0.146781</td>\n",
       "      <td>0.228037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819352</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.353971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363876</td>\n",
       "      <td>0.425767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447642</td>\n",
       "      <td>0.712288</td>\n",
       "      <td>0.648778</td>\n",
       "      <td>0.398361</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.093133</td>\n",
       "      <td>0.316253</td>\n",
       "      <td>0.865735</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.241780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.250396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336269</td>\n",
       "      <td>0.677215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816985</td>\n",
       "      <td>0.338940</td>\n",
       "      <td>0.345265</td>\n",
       "      <td>0.368547</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.591566</td>\n",
       "      <td>0.514479</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>0.547828</td>\n",
       "      <td>0.581093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy  statistics_energy  kurtosis  maximum  minimum      mean  \\\n",
       "0  0.861327           0.739775  0.276290      NaN      NaN  0.298610   \n",
       "1  0.192122           0.029662  0.228647      NaN      NaN  0.317524   \n",
       "2  0.842315           0.739775  0.289534      NaN      NaN  0.324877   \n",
       "3  0.819352           0.698470  0.353971      NaN      NaN  0.363876   \n",
       "4  0.080459           0.036047  0.250396      NaN      NaN  0.336269   \n",
       "\n",
       "   mean_deviation  median  img_range       rms  ...      imc1      imc2  \\\n",
       "0        0.526440     NaN        NaN  0.822848  ...  0.592281  0.585547   \n",
       "1        0.647607     NaN        NaN  0.835276  ...  0.846544  0.314072   \n",
       "2        0.533181     NaN        NaN  0.797732  ...  0.565409  0.580694   \n",
       "3        0.425767     NaN        NaN  0.767108  ...  0.447642  0.712288   \n",
       "4        0.677215     NaN        NaN  0.449141  ...  0.816985  0.338940   \n",
       "\n",
       "       idmn       idn  inverse_variance  maximum_probability  sum_average  \\\n",
       "0  0.614940  0.436165          0.549178             0.112373     0.242410   \n",
       "1  0.653534  0.749143          0.691949             0.280154     0.181031   \n",
       "2  0.601961  0.513437          0.538443             0.140795     0.282003   \n",
       "3  0.648778  0.398361          0.462067             0.093133     0.316253   \n",
       "4  0.345265  0.368547          0.307265             0.591566     0.514479   \n",
       "\n",
       "   sum_entropy  sum_varianc  variance.1  \n",
       "0     0.885271     0.108054    0.187416  \n",
       "1     0.837549     0.133114    0.184223  \n",
       "2     0.876948     0.146781    0.228037  \n",
       "3     0.865735     0.158108    0.241780  \n",
       "4     0.544325     0.547828    0.581093  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_max_scaled = X\n",
    "  \n",
    "for column in df_min_max_scaled.columns:\n",
    "    df_min_max_scaled[column] = ((df_min_max_scaled[column] - df_min_max_scaled[column].min())) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())    \n",
    "  \n",
    "df_min_max_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d0655af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min_max_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "415583f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_min_max_scaled\n",
    "X = X.drop(['maximum', 'minimum', 'median', 'img_range'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b094983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>statistics_energy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_deviation</th>\n",
       "      <th>rms</th>\n",
       "      <th>skewness</th>\n",
       "      <th>std</th>\n",
       "      <th>variance</th>\n",
       "      <th>entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>imc1</th>\n",
       "      <th>imc2</th>\n",
       "      <th>idmn</th>\n",
       "      <th>idn</th>\n",
       "      <th>inverse_variance</th>\n",
       "      <th>maximum_probability</th>\n",
       "      <th>sum_average</th>\n",
       "      <th>sum_entropy</th>\n",
       "      <th>sum_varianc</th>\n",
       "      <th>variance.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861327</td>\n",
       "      <td>0.739775</td>\n",
       "      <td>0.276290</td>\n",
       "      <td>0.298610</td>\n",
       "      <td>0.526440</td>\n",
       "      <td>0.822848</td>\n",
       "      <td>0.766168</td>\n",
       "      <td>0.439110</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.647626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592281</td>\n",
       "      <td>0.585547</td>\n",
       "      <td>0.614940</td>\n",
       "      <td>0.436165</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.112373</td>\n",
       "      <td>0.242410</td>\n",
       "      <td>0.885271</td>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.187416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192122</td>\n",
       "      <td>0.029662</td>\n",
       "      <td>0.228647</td>\n",
       "      <td>0.317524</td>\n",
       "      <td>0.647607</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.750256</td>\n",
       "      <td>0.568495</td>\n",
       "      <td>0.561425</td>\n",
       "      <td>0.497126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846544</td>\n",
       "      <td>0.314072</td>\n",
       "      <td>0.653534</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.691949</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.181031</td>\n",
       "      <td>0.837549</td>\n",
       "      <td>0.133114</td>\n",
       "      <td>0.184223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842315</td>\n",
       "      <td>0.739775</td>\n",
       "      <td>0.289534</td>\n",
       "      <td>0.324877</td>\n",
       "      <td>0.533181</td>\n",
       "      <td>0.797732</td>\n",
       "      <td>0.732021</td>\n",
       "      <td>0.454570</td>\n",
       "      <td>0.447424</td>\n",
       "      <td>0.659366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565409</td>\n",
       "      <td>0.580694</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.513437</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>0.140795</td>\n",
       "      <td>0.282003</td>\n",
       "      <td>0.876948</td>\n",
       "      <td>0.146781</td>\n",
       "      <td>0.228037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819352</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.353971</td>\n",
       "      <td>0.363876</td>\n",
       "      <td>0.425767</td>\n",
       "      <td>0.767108</td>\n",
       "      <td>0.699666</td>\n",
       "      <td>0.339145</td>\n",
       "      <td>0.332685</td>\n",
       "      <td>0.720926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447642</td>\n",
       "      <td>0.712288</td>\n",
       "      <td>0.648778</td>\n",
       "      <td>0.398361</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.093133</td>\n",
       "      <td>0.316253</td>\n",
       "      <td>0.865735</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.241780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.250396</td>\n",
       "      <td>0.336269</td>\n",
       "      <td>0.677215</td>\n",
       "      <td>0.449141</td>\n",
       "      <td>0.698024</td>\n",
       "      <td>0.651383</td>\n",
       "      <td>0.644838</td>\n",
       "      <td>0.400435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816985</td>\n",
       "      <td>0.338940</td>\n",
       "      <td>0.345265</td>\n",
       "      <td>0.368547</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.591566</td>\n",
       "      <td>0.514479</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>0.547828</td>\n",
       "      <td>0.581093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>0.899411</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.349739</td>\n",
       "      <td>0.376090</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.872532</td>\n",
       "      <td>0.689613</td>\n",
       "      <td>0.345349</td>\n",
       "      <td>0.338833</td>\n",
       "      <td>0.758180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442965</td>\n",
       "      <td>0.703697</td>\n",
       "      <td>0.688179</td>\n",
       "      <td>0.511721</td>\n",
       "      <td>0.557166</td>\n",
       "      <td>0.074255</td>\n",
       "      <td>0.285089</td>\n",
       "      <td>0.941686</td>\n",
       "      <td>0.099370</td>\n",
       "      <td>0.203139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>0.781619</td>\n",
       "      <td>0.772820</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.285812</td>\n",
       "      <td>0.577373</td>\n",
       "      <td>0.716077</td>\n",
       "      <td>0.765196</td>\n",
       "      <td>0.510836</td>\n",
       "      <td>0.503634</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650247</td>\n",
       "      <td>0.511421</td>\n",
       "      <td>0.510184</td>\n",
       "      <td>0.399684</td>\n",
       "      <td>0.451935</td>\n",
       "      <td>0.144753</td>\n",
       "      <td>0.270805</td>\n",
       "      <td>0.807923</td>\n",
       "      <td>0.177638</td>\n",
       "      <td>0.236242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>0.766486</td>\n",
       "      <td>0.797603</td>\n",
       "      <td>0.219489</td>\n",
       "      <td>0.251991</td>\n",
       "      <td>0.634874</td>\n",
       "      <td>0.695353</td>\n",
       "      <td>0.790143</td>\n",
       "      <td>0.579760</td>\n",
       "      <td>0.572738</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670616</td>\n",
       "      <td>0.493550</td>\n",
       "      <td>0.434460</td>\n",
       "      <td>0.387269</td>\n",
       "      <td>0.435715</td>\n",
       "      <td>0.155406</td>\n",
       "      <td>0.250125</td>\n",
       "      <td>0.777107</td>\n",
       "      <td>0.185136</td>\n",
       "      <td>0.225524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>0.862624</td>\n",
       "      <td>0.619989</td>\n",
       "      <td>0.554329</td>\n",
       "      <td>0.553028</td>\n",
       "      <td>0.210376</td>\n",
       "      <td>0.824553</td>\n",
       "      <td>0.495009</td>\n",
       "      <td>0.134028</td>\n",
       "      <td>0.130683</td>\n",
       "      <td>0.949351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>0.935328</td>\n",
       "      <td>0.675946</td>\n",
       "      <td>0.385913</td>\n",
       "      <td>0.456494</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.483760</td>\n",
       "      <td>0.879264</td>\n",
       "      <td>0.247842</td>\n",
       "      <td>0.352722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>0.844701</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.512414</td>\n",
       "      <td>0.516238</td>\n",
       "      <td>0.261210</td>\n",
       "      <td>0.800895</td>\n",
       "      <td>0.534581</td>\n",
       "      <td>0.178734</td>\n",
       "      <td>0.174503</td>\n",
       "      <td>0.921126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145585</td>\n",
       "      <td>0.915978</td>\n",
       "      <td>0.662828</td>\n",
       "      <td>0.403424</td>\n",
       "      <td>0.392072</td>\n",
       "      <td>0.068155</td>\n",
       "      <td>0.468084</td>\n",
       "      <td>0.851636</td>\n",
       "      <td>0.255574</td>\n",
       "      <td>0.342478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        energy  statistics_energy  kurtosis      mean  mean_deviation  \\\n",
       "0     0.861327           0.739775  0.276290  0.298610        0.526440   \n",
       "1     0.192122           0.029662  0.228647  0.317524        0.647607   \n",
       "2     0.842315           0.739775  0.289534  0.324877        0.533181   \n",
       "3     0.819352           0.698470  0.353971  0.363876        0.425767   \n",
       "4     0.080459           0.036047  0.250396  0.336269        0.677215   \n",
       "...        ...                ...       ...       ...             ...   \n",
       "3235  0.899411           0.698470  0.349739  0.376090        0.437417   \n",
       "3236  0.781619           0.772820  0.257900  0.285812        0.577373   \n",
       "3237  0.766486           0.797603  0.219489  0.251991        0.634874   \n",
       "3238  0.862624           0.619989  0.554329  0.553028        0.210376   \n",
       "3239  0.844701           0.632381  0.512414  0.516238        0.261210   \n",
       "\n",
       "           rms  skewness       std  variance   entropy  ...      imc1  \\\n",
       "0     0.822848  0.766168  0.439110  0.432012  0.647626  ...  0.592281   \n",
       "1     0.835276  0.750256  0.568495  0.561425  0.497126  ...  0.846544   \n",
       "2     0.797732  0.732021  0.454570  0.447424  0.659366  ...  0.565409   \n",
       "3     0.767108  0.699666  0.339145  0.332685  0.720926  ...  0.447642   \n",
       "4     0.449141  0.698024  0.651383  0.644838  0.400435  ...  0.816985   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3235  0.872532  0.689613  0.345349  0.338833  0.758180  ...  0.442965   \n",
       "3236  0.716077  0.765196  0.510836  0.503634  0.571953  ...  0.650247   \n",
       "3237  0.695353  0.790143  0.579760  0.572738  0.534591  ...  0.670616   \n",
       "3238  0.824553  0.495009  0.134028  0.130683  0.949351  ...  0.122586   \n",
       "3239  0.800895  0.534581  0.178734  0.174503  0.921126  ...  0.145585   \n",
       "\n",
       "          imc2      idmn       idn  inverse_variance  maximum_probability  \\\n",
       "0     0.585547  0.614940  0.436165          0.549178             0.112373   \n",
       "1     0.314072  0.653534  0.749143          0.691949             0.280154   \n",
       "2     0.580694  0.601961  0.513437          0.538443             0.140795   \n",
       "3     0.712288  0.648778  0.398361          0.462067             0.093133   \n",
       "4     0.338940  0.345265  0.368547          0.307265             0.591566   \n",
       "...        ...       ...       ...               ...                  ...   \n",
       "3235  0.703697  0.688179  0.511721          0.557166             0.074255   \n",
       "3236  0.511421  0.510184  0.399684          0.451935             0.144753   \n",
       "3237  0.493550  0.434460  0.387269          0.435715             0.155406   \n",
       "3238  0.935328  0.675946  0.385913          0.456494             0.026580   \n",
       "3239  0.915978  0.662828  0.403424          0.392072             0.068155   \n",
       "\n",
       "      sum_average  sum_entropy  sum_varianc  variance.1  \n",
       "0        0.242410     0.885271     0.108054    0.187416  \n",
       "1        0.181031     0.837549     0.133114    0.184223  \n",
       "2        0.282003     0.876948     0.146781    0.228037  \n",
       "3        0.316253     0.865735     0.158108    0.241780  \n",
       "4        0.514479     0.544325     0.547828    0.581093  \n",
       "...           ...          ...          ...         ...  \n",
       "3235     0.285089     0.941686     0.099370    0.203139  \n",
       "3236     0.270805     0.807923     0.177638    0.236242  \n",
       "3237     0.250125     0.777107     0.185136    0.225524  \n",
       "3238     0.483760     0.879264     0.247842    0.352722  \n",
       "3239     0.468084     0.851636     0.255574    0.342478  \n",
       "\n",
       "[3240 rows x 32 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31cfbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def sens_spec(y_test, y_pred):\n",
    "    cm1 = confusion_matrix(y_test, y_pred)\n",
    "    print(cm1)\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44bb674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=2),\n",
       "                   learning_rate=0.01, n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=2),\n",
       "                   learning_rate=0.01, n_estimators=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=2)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=2),\n",
       "                   learning_rate=0.01, n_estimators=100)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[['HYPOTHESIS']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "clf=AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=2),n_estimators=100,learning_rate=0.01)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "639f2b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.76      0.69       118\n",
      "           1       0.94      0.90      0.92       530\n",
      "\n",
      "    accuracy                           0.88       648\n",
      "   macro avg       0.79      0.83      0.81       648\n",
      "weighted avg       0.89      0.88      0.88       648\n",
      "\n",
      "[[ 90  51]\n",
      " [ 28 479]]\n",
      "Accuracy :  0.8780864197530864\n",
      "Sensitivity :  0.6382978723404256\n",
      "Specificity :  0.9447731755424064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred, y_test))\n",
    "sens_spec(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8e6cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f881f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8811728395061729"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "418ae53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(clf, open(\"rfcboostingImgFeatures.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb164b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=101),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=96)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=101),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=96)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=101)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=101)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=101),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=96)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:-1]\n",
    "y=df[['HYPOTHESIS']]\n",
    "pca=PCA(n_components=36)\n",
    "X_PCA=pca.fit_transform(X)\n",
    "X_PCA=pd.DataFrame(X_PCA)\n",
    "FINAL_X_SET = pd.concat([X, X_PCA], axis=1, join='inner')\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(FINAL_X_SET, y, test_size = 0.2, random_state = 1)\n",
    "clf=AdaBoostClassifier(random_state=96,base_estimator=RandomForestClassifier(random_state=101),n_estimators=100,learning_rate=0.01)\n",
    "clf.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "790865c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9027777777777778"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2705e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.84      0.75       116\n",
      "           1       0.96      0.92      0.94       532\n",
      "\n",
      "    accuracy                           0.90       648\n",
      "   macro avg       0.83      0.88      0.85       648\n",
      "weighted avg       0.91      0.90      0.91       648\n",
      "\n",
      "[[ 97  44]\n",
      " [ 19 488]]\n",
      "Accuracy :  0.9027777777777778\n",
      "Sensitivity :  0.6879432624113475\n",
      "Specificity :  0.9625246548323472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "sens_spec(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9db30219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.82      0.73       113\n",
      "           1       0.96      0.91      0.93       535\n",
      "\n",
      "    accuracy                           0.90       648\n",
      "   macro avg       0.81      0.87      0.83       648\n",
      "weighted avg       0.91      0.90      0.90       648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,1:-1]\n",
    "y=df[['HYPOTHESIS']]\n",
    "pca=PCA(n_components=36)\n",
    "X_PCA=pca.fit_transform(X)\n",
    "FINAL_X_SET=pd.DataFrame(X_PCA)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(FINAL_X_SET, y, test_size = 0.2, random_state = 1)\n",
    "clf=AdaBoostClassifier(random_state=96,base_estimator=RandomForestClassifier(random_state=101),n_estimators=100,learning_rate=0.01)\n",
    "clf.fit(X_train, y_train.values.ravel()) \n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))\n",
    "sens_spec(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c749345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950617283950617"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4371dcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09f53fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93,  48],\n",
       "       [ 20, 487]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "702dfe95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ca6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
